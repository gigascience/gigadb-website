---
# Use bastion server to restore PostgreSQL database on RDS instance



- name: Fix Centos EOL issues
  hosts: name_bastion_server_staging*:name_bastion_server_live*
  roles:
    - role: ../../roles/centos-eol-fix

- name: Setup Fail2ban
  hosts: name_bastion_server_staging*:name_bastion_server_live*

  tasks:
    - debug:
        msg: "remote private ip : {{ ec2_bastion_private_ip }}"

  roles:
    - role: ../../roles/fail2ban
    - role: ../../roles/jail-ssh

- name: Restore PostgreSQL database on RDS instance using pg_restore
  hosts: name_bastion_server_staging*:name_bastion_server_live*

  tasks:
    - name: Disable postgresql module in AppStream
      command: dnf -qy module disable postgresql
      become: yes

    - rpm_key:
        state: present
        key: https://download.postgresql.org/pub/repos/yum/RPM-GPG-KEY-PGDG

    - name: Install PostgreSQL repo
      become: yes
      dnf:
        name: https://download.postgresql.org/pub/repos/yum/reporpms/EL-8-x86_64/pgdg-redhat-repo-latest.noarch.rpm
        state: present

    - name: Install PostgreSQL 14 client packages
      become: yes
      dnf:
        name: postgresql14
        state: present

    - name: Test pg_isready can connect to RDS instance
      ansible.builtin.command: "/usr/pgsql-14/bin/pg_isready -h {{ pg_host }}"
      register: pg_isready
    - debug: msg="{{ pg_isready.stdout }}"

    - name: Copy specified backup file from files-url-updater tool to bastion server
      ansible.builtin.copy:
        src: '{{ backup_file }}'
        dest: "/home/centos/database_bootstrap.backup"
        owner: centos
        group:
      when: backup_file

- name: Setup files-url-updater so to load latest DB backup in RDS daily
  hosts: name_bastion_server_staging*:name_bastion_server_live*
  vars:
    target_host: _bastion

  tasks:
    - name: Create a backups directory for storing database dump files
      ansible.builtin.file:
        path: "{{ item }}"
        state: directory
        mode: '0755'
        owner: centos
        group: centos
      loop:
        - "/home/centos/downloads"
        - "/home/centos/converted"

    - name: Install new wrapper script to reset database
      ansible.builtin.copy:
        src: "../../../../gigadb/app/tools/files-url-updater/databaseReset.sh"
        dest: /home/centos/
        owner: centos
        group: centos
        mode: a+x

    - name: Create a bin and log directory (for composer and cronjob logging) if it does not exist
      ansible.builtin.file:
        path: "/home/centos/{{ item }}"
        state: directory
        mode: '0755'
        owner: centos
        group: centos
      loop:
        - "logs"

    - name: Setup cronjob to reset database daily after a new backup is available on the ftp server
      ansible.builtin.cron:
        name: "Reset database every day after a new backup is available on the ftp server"
        minute: "05"
        hour: "10"
        user: "centos"
        job: "./databaseReset.sh 2> $HOME/logs/errors.log 1> $HOME/logs/output.log"
        state: "{{ reset_database_cronjob_state }}"

    - name: Install docker-compose
      pip:
        name: docker-compose==1.23

    - name: Create .env with RDS DSN
      template:
        src: ../../../../gigadb/app/tools/files-url-updater/bastion-env.j2
        dest: /home/centos/.env
        owner: root
        group: root
        mode: 0644

  roles:
    - role: ../../roles/docker-install
    - role: role-secure-docker-daemon
      dds_host: "{{ ec2_bastion_public_ip }}"
      dds_server_cert_path: /etc/docker
      dds_restart_docker: no
      dds_client_cert_path: /home/centos/.docker
    - role: ../../roles/docker-postinstall
    - role: ../../roles/docker-daemon-enable-start

- name: Setup Excel to GigaDB tool
  hosts: name_bastion_server_staging*:name_bastion_server_live*

  tasks:
    - name: Copy dataset upload tool shell script
      ansible.builtin.copy:
        src: "../../../../gigadb/app/tools/excel-spreadsheet-uploader/execute.sh"
        dest: /home/centos/datasetUpload.sh
        owner: centos
        group: centos
        mode: a+x

    - name: Copy dataset upload tool shell post upload script
      ansible.builtin.copy:
        src: "../../../../gigadb/app/tools/excel-spreadsheet-uploader/postUpload.sh"
        dest: /home/centos/
        owner: centos
        group: centos
        mode: a+x

    - name: Create env file for database  (for pg_client docker service)
      ansible.builtin.template:
        src: ../../../../gigadb/app/tools/excel-spreadsheet-uploader/env.j2
        dest: /home/centos/db-env
        owner: centos
        group: centos
        mode: 0644

    - name: Create directories for dataset upload operations
      ansible.builtin.file:
        path: "{{ item }}"
        state: directory
        mode: '0755'
        owner: centos
        group: centos
      loop:
        - "/home/centos/uploadLogs"
        - "/home/centos/uploadDir"

    - name: Ensure centos user has GIGADB_ENV set
      ansible.builtin.lineinfile:
        path: /home/centos/.bash_profile
        insertafter: '# User specific environment and startup programs\n'
        line: "GIGADB_ENV={{ gigadb_environment }}"

    - name: Ensure centos user has GITLAB_PROJECT set
      ansible.builtin.lineinfile:
        path: /home/centos/.bash_profile
        insertafter: '# User specific environment and startup programs\n'
        line: "GITLAB_PROJECT={{ gitlab_project }}"

- name: Create setup for generating and uploading database dump files to S3
  hosts: name_bastion_server_staging*:name_bastion_server_live*

  tasks:
  - name: Create a /home/centos/.config/rclone directory
    ansible.builtin.file:
      path: /home/centos/.config/rclone
      state: directory
      mode: '0755'
      owner: centos
      group: centos

  - name: Create AWS S3 configuration for rclone
    template:
      src: ../../../../ops/configuration/rclone-conf/rclone.conf.j2
      dest: /home/centos/.config/rclone/rclone.conf
      owner: root
      group: root
      mode: 0644

  - name: Create a backups directory for storing database dump files
    ansible.builtin.file:
      path: "{{ item }}"
      state: directory
      mode: '0755'
      owner: centos
      group: centos
    loop:
      - "/home/centos/backups"

  - name: Setup cronjob to automate copying database backup file to S3
    ansible.builtin.cron:
      name: "Create database dump file from RDS and upload to S3 every day"
      minute: "00"
      hour: "11"
      user: "centos"
      job: "docker run --env-file .env -v /home/centos/backups:/backups -v /home/centos/.config/rclone/rclone.conf:/root/.config/rclone/rclone.conf registry.gitlab.com/{{ gitlab_project }}/production_s3backup:{{ gigadb_environment }}"
      state: "{{ upload_database_backup_to_S3_cronjob_state }}"

- name: Setup Disk usage monitoring tool
  hosts: name_bastion_server_staging*:name_bastion_server_live*

  tasks:
    - name: Create the diskUsage monitoring script
      ansible.builtin.copy:
        content: 'df -h | grep /dev/ | cut -d " " -f10 | cut -d% -f1'
        dest: /home/centos/diskUsage
        owner: centos
        group: centos
        mode: a+x

    - name: Create the Gitter notify script
      ansible.builtin.copy:
        content: "source /home/centos/.env;curl -X POST -i -H \"Content-Type: application/json\" -H \"Accept: application/json\" -H \"Authorization: Bearer $GITTER_API_TOKEN\" \"https://api.gitter.im/v1/rooms/$GITTER_IT_NOTIFICATION_ROOM_ID/chatMessages\"  -d '{\"text\":\"Disk space usage requires attention on '\"$DEPLOYMENT_TIER-$GIGADB_ENVIRONMENT\"': '\"$1\"'%\"}'"
        dest: /home/centos/notify
        owner: centos
        group: centos
        mode: a+x

    - name: Copy swatch config file
      ansible.builtin.copy:
        src: "{{ item }}"
        dest: /home/centos/
        owner: centos
        group: centos
      loop:
          - "../../../../gigadb/app/tools/disk-usage-monitor/swatch.conf"
          - "../../../../gigadb/app/tools/disk-usage-monitor/check-swatch.conf"

    - name: Install swatch packages
      become: yes
      dnf:
        name: swatch
        state: present

    - name: Setup cronjob to automate disk usage monitoring
      ansible.builtin.cron:
        name: "Check daily the disk usage and notify from 50%"
        minute: "00"
        hour: "23"
        user: "centos"
        job: "swatch -c swatch.conf -p ./diskUsage"

- name: Setup create readme tool
  hosts: name_bastion_server_staging*:name_bastion_server_live*
  tags:
    - readme_tool

  tasks:
    - name: Copy readme tool shell script
      ansible.builtin.copy:
        src: "../../../../gigadb/app/tools/readme-generator/createReadme.sh"
        dest: /home/centos/createReadme.sh
        owner: centos
        group: centos
        mode: a+x

    # Files created by readme tool container can be accessed in this directory
    - name: Create a directory where readme files can be saved to
      ansible.builtin.file:
        path: /home/centos/readmeFiles
        state: directory
        mode: '0755'
        owner: centos
        group: centos

- name: Set up and configuration of rclone on bastion server
  hosts: name_bastion_server_staging*:name_bastion_server_live*
  
  tasks:
    - name: Install rclone
      ansible.builtin.include_role:
        name: ansible-rclone
      vars:
        rclone_version: "1.60.0"
        rclone_arch: "amd64"
        install_manpages: "true"
        rclone_config_location: "/home/centos/.config/rclone/rclone.conf"

- name: Load latest DB backup
  hosts: name_bastion_server_staging*:name_bastion_server_live*

  tasks:
  - name: Load latest database into this environment's RDS instance
    ansible.builtin.shell: "./databaseReset.sh {{ backupDate }}"
    args:
      chdir: /home/centos
      executable: /bin/bash
    register: reset_database_output

  - debug:
      msg: "reset database stdout : {{ reset_database_output.stdout }}"

  - debug:
      msg: "reset database stderr : {{ reset_database_output.stderr }}"

- name: Install node exporter
  hosts: name_bastion_server_staging*:name_bastion_server_live*
  tags:
    - node-exporter
  roles:
    - prometheus.prometheus.node_exporter