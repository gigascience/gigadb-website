---
# Use bastion server to restore PostgreSQL database on RDS instance



- name: Fix Centos EOL issues
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - fix-centos-eol-issues

  roles:
    - role: ../../roles/centos-eol-fix

- name: Setup Fail2ban
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - setup-fail2ban

  tasks:
    - debug:
        msg: "remote private ip : {{ ec2_bastion_private_ip }}"

  roles:
    - role: ../../roles/fail2ban
    - role: ../../roles/jail-ssh

- name: Setup Docker CE
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - setup-docker-ce
  vars:
    target_host: _bastion

  roles:
    - role: ../../roles/docker-install
    - role: role-secure-docker-daemon
      dds_host: "{{ ec2_bastion_public_ip }}"
      dds_server_cert_path: /etc/docker
      dds_restart_docker: no
      dds_client_cert_path: /home/centos/.docker
    - role: ../../roles/docker-postinstall
    - role: ../../roles/docker-daemon-enable-start


- name: Restore PostgreSQL database on RDS instance using pg_restore
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - restore-db-on-rds

  tasks:
    - name: Disable postgresql module in AppStream
      command: dnf -qy module disable postgresql
      become: yes

    - rpm_key:
        state: present
        key: https://download.postgresql.org/pub/repos/yum/keys/PGDG-RPM-GPG-KEY-RHEL

    - name: Install PostgreSQL repo
      become: yes
      dnf:
        name: https://download.postgresql.org/pub/repos/yum/reporpms/EL-8-x86_64/pgdg-redhat-repo-latest.noarch.rpm
        state: present

    - name: Install PostgreSQL 14 client packages
      become: yes
      dnf:
        name: postgresql14
        state: present

    - name: Test pg_isready can connect to RDS instance
      ansible.builtin.command: "/usr/pgsql-14/bin/pg_isready -h {{ pg_host }}"
      register: pg_isready
    - debug: msg="{{ pg_isready.stdout }}"

    - name: Copy specified backup file from files-url-updater tool to bastion server
      ansible.builtin.copy:
        src: '{{ backup_file }}'
        dest: "/home/centos/database_bootstrap.backup"
        owner: centos
        group:
      when: backup_file

- name: Setup files-url-updater so to load latest DB backup in RDS daily
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - files-url-updater
  vars:
    target_host: _bastion

  tasks:
    - name: Create a backups directory for storing database dump files
      ansible.builtin.file:
        path: "{{ item }}"
        state: directory
        mode: '0755'
        owner: centos
        group: centos
      loop:
        - "/home/centos/downloads"
        - "/home/centos/converted"
        - "/home/centos/restore"

    - name: Install new wrapper script to reset database
      ansible.builtin.copy:
        src: "../../../../gigadb/app/tools/files-url-updater/databaseReset.sh"
        dest: /usr/local/bin/databaseReset
        owner: centos
        group: centos
        mode: a+x

    - name: Create a bin and log directory (for composer and cronjob logging) if it does not exist
      ansible.builtin.file:
        path: "/home/centos/{{ item }}"
        state: directory
        mode: '0755'
        owner: centos
        group: centos
      loop:
        - "logs"

    - name: Setup cronjob to reset database daily after a new backup is available on the ftp server
      ansible.builtin.cron:
        name: "Reset database every day after a new backup is available on the ftp server"
        minute: "05"
        hour: "10"
        user: "centos"
        job: "/usr/local/bin/databaseReset 2> $HOME/logs/errors.log 1> $HOME/logs/output.log"
        state: "{{ reset_database_cronjob_state }}"

    - name: Install docker-compose
      pip:
        name: docker-compose==1.23

    - name: Create .env with RDS DSN
      template:
        src: ../../../../gigadb/app/tools/files-url-updater/bastion-env.j2
        dest: /home/centos/.env
        owner: root
        group: root
        mode: 0644

- name: Setup Excel to GigaDB tool
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - excel-spreadsheet-uploader

  tasks:
    - name: Copy dataset upload tool shell script
      ansible.builtin.copy:
        src: "../../../../gigadb/app/tools/excel-spreadsheet-uploader/execute.sh"
        dest: /usr/local/bin/datasetUpload
        owner: centos
        group: centos
        mode: a+x

    - name: Copy dataset upload tool shell post upload script
      ansible.builtin.copy:
        src: "../../../../gigadb/app/tools/excel-spreadsheet-uploader/postUpload.sh"
        dest: /usr/local/bin/postUpload
        owner: centos
        group: centos
        mode: a+x

    - name: Copy script for updating the md5 values and file size to db
      ansible.builtin.copy:
        src: "../../../../gigadb/app/tools/excel-spreadsheet-uploader/filesMetaToDb.sh"
        dest: /usr/local/bin/filesMetaToDb
        owner: centos
        group: centos
        mode: a+x

    - name: Create env file for database  (for pg_client docker service)
      ansible.builtin.template:
        src: ../../../../gigadb/app/tools/excel-spreadsheet-uploader/env.j2
        dest: /home/centos/db-env
        owner: centos
        group: centos
        mode: 0644

    - name: Create directories for dataset upload operations
      ansible.builtin.file:
        path: "{{ item }}"
        state: directory
        mode: '0755'
        owner: centos
        group: centos
      loop:
        - "/home/centos/uploadLogs"
        - "/home/centos/uploadDir"

    - name: Ensure centos user has GIGADB_ENV set
      ansible.builtin.lineinfile:
        path: /home/centos/.bash_profile
        insertafter: '# User specific environment and startup programs\n'
        line: "GIGADB_ENV={{ gigadb_environment }}"

    - name: Ensure centos user has GITLAB_PROJECT set
      ansible.builtin.lineinfile:
        path: /home/centos/.bash_profile
        insertafter: '# User specific environment and startup programs\n'
        line: "GITLAB_PROJECT={{ gitlab_project }}"

- name: Create AWS credentials file
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - create-metadata-bucket-credentials-file

  tasks:
  - name: Create a /etc/aws directory for the metadata
    ansible.builtin.file:
      path: "/etc/aws"
      state: directory
      mode: '0755'
      owner: centos
      group: centos

  - name: Create AWS credential file for access to AWS S3 metadata bucket
    template:
      src: ../../../../ops/configuration/aws-conf/credentials.j2
      dest: "/etc/aws/credentials"
      owner: centos
      group: centos
      mode: 0644

- name: Create setup for generating and uploading database dump files to S3
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - setup-uploading-db-dump-to-s3

  tasks:
  - name: Create a /home/centos/.config/rclone directory
    ansible.builtin.file:
      path: /home/centos/.config/rclone
      state: directory
      mode: '0755'
      owner: centos
      group: centos

  - name: Create AWS S3 configuration for rclone
    template:
      src: ../../../../ops/configuration/rclone-conf/rclone.conf.j2
      dest: /home/centos/.config/rclone/rclone.conf
      owner: root
      group: root
      mode: 0644

  - name: Create a backups directory for storing database dump files
    ansible.builtin.file:
      path: "{{ item }}"
      state: directory
      mode: '0755'
      owner: centos
      group: centos
    loop:
      - "/home/centos/backups"

  - name: Setup cronjob to refresh the materialized view of the database
    ansible.builtin.cron:
      name: "Refresh the materialized view of the database every day"
      minute: "00"
      hour: "20"
      user: "centos"
      job: 'echo "$(date +\%y\%m\%d_\%H\%M\%S) - Refresh materialized views start..." >> /home/centos/logs/refresh_materialized_views_daily.log
        && docker run --rm  --env-file ./db-env registry.gitlab.com/{{ gitlab_project }}/production_pgclient:{{ gigadb_environment }} -c "REFRESH MATERIALIZED VIEW FILE_FINDER; REFRESH MATERIALIZED VIEW SAMPLE_FINDER; REFRESH MATERIALIZED VIEW DATASET_FINDER;" >> /home/centos/logs/refresh_materialized_views_daily.log 2>&1
        && echo "$(date +\%y\%m\%d_\%H\%M\%S) - Refresh materialized views completed!" >> /home/centos/logs/refresh_materialized_views_daily.log'

  - name: Setup cronjob to automate copying database backup file to S3
    ansible.builtin.cron:
      name: "Create database dump file from RDS and upload to S3 every day"
      minute: "00"
      hour: "22"
      user: "centos"
      job: "docker run --env-file .env -v /home/centos/backups:/backups -v /home/centos/.config/rclone/rclone.conf:/root/.config/rclone/rclone.conf registry.gitlab.com/{{ gitlab_project }}/production_s3backup:{{ gigadb_environment }}"
      state: "{{ upload_database_backup_to_S3_cronjob_state }}"

- name: Setup Disk usage monitoring tool
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - swatch-tool

  tasks:
    - name: Create the diskUsage monitoring script
      ansible.builtin.copy:
        content: 'df -h | grep /dev/ | cut -d " " -f10 | cut -d% -f1'
        dest: /home/centos/diskUsage
        owner: centos
        group: centos
        mode: a+x

    - name: Create the Gitter notify script
      ansible.builtin.copy:
        content: "source /home/centos/.env;curl -X POST -i -H \"Content-Type: application/json\" -H \"Accept: application/json\" -H \"Authorization: Bearer $GITTER_API_TOKEN\" \"https://api.gitter.im/v1/rooms/$GITTER_IT_NOTIFICATION_ROOM_ID/chatMessages\"  -d '{\"text\":\"Disk space usage requires attention on '\"$DEPLOYMENT_TIER-$GIGADB_ENVIRONMENT\"': '\"$1\"'%\"}'"
        dest: /home/centos/notify
        owner: centos
        group: centos
        mode: a+x

    - name: Copy swatch config file
      ansible.builtin.copy:
        src: "{{ item }}"
        dest: /home/centos/
        owner: centos
        group: centos
      loop:
          - "../../../../gigadb/app/tools/disk-usage-monitor/swatch.conf"
          - "../../../../gigadb/app/tools/disk-usage-monitor/check-swatch.conf"

    - name: Install swatch packages
      become: yes
      dnf:
        name: swatch
        state: present

    - name: Setup cronjob to automate disk usage monitoring
      ansible.builtin.cron:
        name: "Check daily the disk usage and notify from 50%"
        minute: "00"
        hour: "23"
        user: "centos"
        job: "swatch -c swatch.conf -p ./diskUsage"

- name: Setup create readme tool
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - readme-tool

  tasks:
    - name: Copy readme tool shell script
      ansible.builtin.copy:
        src: "../../../../gigadb/app/tools/readme-generator/createReadme.sh"
        dest: /usr/local/bin/createReadme
        owner: centos
        group: centos
        mode: a+x

    # Files created by readme tool container can be accessed in this directory
    - name: Create a directory where readme files can be saved to
      ansible.builtin.file:
        path: /home/centos/readmeFiles
        state: directory
        mode: '0755'
        owner: centos
        group: centos

- name: Setup files metadata console tool
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - files-metadata-tool

  tasks:
    # Used to transform dataset ftp_site and file location URLs
    - name: Copy shell script
      ansible.builtin.copy:
        src: "../../../../gigadb/app/tools/files-metadata-console/scripts/updateUrls.sh"
        dest: /usr/local/bin/updateUrls
        owner: centos
        group: centos
        mode: a+x

    - name: Copy shell script for calculating the file sizes and md5
      ansible.builtin.copy:
        src: "../../../../gigadb/app/tools/files-metadata-console/scripts/md5.sh"
        dest: /usr/local/bin/calculateChecksumSizes
        owner: centos
        group: centos
        mode: a+x
          
    - name: Install gum
      ansible.builtin.yum:
        name: https://github.com/charmbracelet/gum/releases/download/v0.14.1/gum-0.14.1-1.x86_64.rpm
        state: present
        disable_gpg_check: true

    - name: Install new wrapper script for files comparison tools
      ansible.builtin.copy:
        src: "../../../../gigadb/app/tools/files-metadata-console/scripts/compare_files.sh"
        dest: /usr/local/bin/compare
        owner: centos
        group: centos
        mode: a+x

- name: Set up transfer files tool
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - transfer-tool

  tasks:
    - name: Create env file for backup
      ansible.builtin.template:
        src: ../../../../gigadb/app/tools/transfer-files/config-sources/files-env.j2
        dest: /home/centos/files-env
        owner: centos
        group: centos
        mode: 0644

    - name: Create directory for storing log output
      ansible.builtin.file:
        path: /var/log/gigadb
        state: directory
        mode: '0777'
        owner: centos
        group: centos

    - name: Create a .aws directory for the centos user
      ansible.builtin.file:
        path: "/home/centos/.aws"
        state: directory
        mode: '0755'
        owner: centos
        group: centos

    - name: Create aws credentials file
      ansible.builtin.template:
        src: ../../../../ops/configuration/aws-conf/credentials.j2
        dest: "/home/centos/.aws/credentials"
        owner: centos
        group: centos
        mode: 0644

    - name: Copy wrapper script to backup files to wasabi bucket and s3 bucket
      ansible.builtin.copy:
        src: "../../../../gigadb/app/tools/transfer-files/scripts/transfer.sh"
        dest: /usr/local/bin/transfer
        owner: centos
        group: centos
        mode: a+x

- name: Setup sync dropbox tool
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - sync-dropbox-tool

  tasks:
    block:
      - name: Copy rclone config for dropbox sync
        ansible.builtin.copy:
          src: "../../../../gigadb/app/tools/sync-dropbox/config-sources/rclone.conf.dist"
          dest: /etc/sync_dropbox/rclone.conf
          owner: centos
          group: centos
          mode: 0644

      - name: Copy the wrapper script to sync dropbox from upstream to alt
        ansible.builtin.copy:
          src: "../../../../gigadb/app/tools/sync-dropbox/scripts/sync_dropbox.sh"
          dest: /usr/local/bin/sync_dropbox
          owner: centos
          group: centos
          mode: a+x

      - name: get private key of upstream
        ansible.builtin.uri:
          url: "{{ gitlab_misc_url }}/variables/id_rsa_aws_hk_gigadb_pem"
          method: GET
          headers:
            PRIVATE-TOKEN: "{{ gitlab_private_token }}"
          body_format: json
          status_code:
            - 200
        register: private_key_from_gl

      - name: copy public key
        ansible.builtin.copy:
          content: "{{ public_key_from_gl.json.value  }}"
          dest: "/home/centos/.ssh/id-rsa-aws-hk-gigadb.pem"
          owner: "{{ centos }}"
          group: "{{ centos }}"
          mode: g-rw,o-rw
    when: private_key_from_gl.status == 200

- name: Set up and configuration of rclone on bastion server
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - rclone-tool
  
  tasks:
    - name: Install rclone
      ansible.builtin.include_role:
        name: ansible-rclone
      vars:
        rclone_version: "1.60.0"
        rclone_arch: "amd64"
        install_manpages: "true"
        rclone_config_location: "/home/centos/.config/rclone/rclone.conf"

- name: Mount AWS efs access points
  hosts: name_bastion_server_{{gigadb_env}}*
  become: yes
  tags:
    - mount-efs

  tasks:
    - name: Download custom build aws efs utils binary
      ansible.builtin.get_url:
        url: https://s3.ap-northeast-1.wasabisys.com/infra-resources/amazon-efs-utils-2.0.4-1.el8.x86_64.rpm
        dest: /tmp/aws-efs-utils.rpm

    - name: Install the aws efs utils binary
      dnf:
        name: /tmp/aws-efs-utils.rpm
        state: present
        disable_gpg_check: yes

    - name: Create directories for mounting
      ansible.builtin.file:
        path: "{{ item }}"
        state: directory
        mode: '0755'
        owner: centos
        group: centos
      loop:
        - "/share/dropbox"
        - "/share/config"

    - name: Mount the dropbox access points
      ansible.posix.mount:
        path: "/share/dropbox"
        src: "{{ efs_filesystem_dns_name }}"
        fstype: efs
        opts: tls,accesspoint={{ dropbox_area_id }}
        state: mounted

    - name: Confirm the dropbox access point is mounted
      ansible.builtin.command:
        cmd: mountpoint /share/dropbox
      register: dropbox_mount_check
      changed_when: false
      failed_when: dropbox_mount_check.stdout == "/share/dropbox is not a mountpoint"

    - name: Mount the config access points
      ansible.posix.mount:
        path: "/share/config"
        src: "{{ efs_filesystem_dns_name }}"
        fstype: efs
        opts: tls,accesspoint={{ configuration_area_id }}
        state: mounted

    - name: Confirm the config access point is mounted
      ansible.builtin.command:
        cmd: mountpoint /share/config
      register: config_mount_check
      changed_when: false
      failed_when: config_mount_check.stdout == "/share/config is not a mountpoint"

    - name: Remove custom build aws efs utils rpm
      ansible.builtin.file:
        path: /tmp/aws-efs-utils.rpm
        state: absent

- name: Load latest DB backup
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - load-latest-db

  tasks:
  - name: Load latest database into this environment's RDS instance
    ansible.builtin.shell: "/usr/local/bin/databaseReset {{ backupDate }}"
    args:
      chdir: /home/centos
      executable: /bin/bash
    register: reset_database_output

  - debug:
      msg: "reset database stdout : {{ reset_database_output.stdout }}"

  - debug:
      msg: "reset database stderr : {{ reset_database_output.stderr }}"

- name: Install node exporter
  hosts: name_bastion_server_{{gigadb_env}}*
  tags:
    - node-exporter
  roles:
    - prometheus.prometheus.node_exporter
