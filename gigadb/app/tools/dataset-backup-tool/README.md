# Tools for GigaDB: dataset-backup-tool

## Set up

To run the Tencent backup smoke tests, the tests need access to a Tencent Cloud
account which is provided by these variables: `TENCENTCLOUD_SECRET_ID`,
`TENCENTCLOUD_SECRET_KEY`, `TENCENTCLOUD_APP_ID`. These variables need to be 
added as new GitLab secrets. 

These new variables need to be pulled into the `.secrets` file and a 
configuration file, `.cos.conf` and shell scripts, `create_bucket.sh` and `
delete_bucket.sh` created in the `dataset-backup-tool/scripts` directory:
```
$ docker-compose run --rm config
```
The smoke tests uses these shell scripts for creating and deleting a Tencent 
bucket at the start and end of the tests. The `.cos.conf` file provides 
configuration for running `coscmd` commands in `BackupSmokeCest` functional test 
class.

## Run Tencent coscmd based backup smoke tests

Change directory to the `dataset-backup-tool`:
```
$ cd gigadb/app/tools/dataset-backup-tool
```

There are 3 smoke tests in `tests/functional/BackupSmokeCest` which backup data
files to a `dataset` directory in a Tencent bucket:
* `tryBackupDataset` will upload 3 files from the `tests/_data/dataset1` 
  directory into the `dataset` directory in a Tencent bucket.
* `tryUpdateBackupWithChangedFile` checks that the `coscmd` tool can detect 
  differences between files. This test should only upload `test.csv` from
  `tests/_data/dataset2` into the Tencent `dataset` backup directory since only 
  this csv file is different in the `dataset2` directory compared to the 
  `dataset1` directory.
* `tryUpdateBackupWithDeletedFile` checks that the `--delete` parameter is able
  to synchronise the contents of a source directory with its counterpart 
  directory in a Tencent bucket. The `tests/_data/dataset3` directory is missing
  `test.tsv` so this test checks that the `test.tsv` file in the Tencent bucket 
  `dataset` directory has been deleted.

To run these smoke tests:
```
$ docker-compose run --rm backup_tool ./vendor/bin/codecept run tests/functional/BackupSmokeCest.php
```

## RClone

### Setup

Rclone is the recommended approach for operating the backup workflows.
``gigadb/app/tools/dataset-backup-tool/config/rclone.conf`` is the configuration file to enable rclone to operate on Tencent Cloud.
That configuration is generated by the same ``generate_config.sh`` aforementioned
based on the template ``gigadb/app/tools/dataset-backup-tool/config/rclone.conf.dist``

The setup has its own smoke tests that can be run using this way:
```
$ cd gigadb/app/tools/dataset-backup-tool
$ docker-compose run --rm backup_tool ./vendor/bin/codecept run -g rclone-setup tests/functional
```

For the benefit of the tests, the configuration file is bind-mounted to the ``backup_tool`` 
container service in ``gigadb/app/tools/dataset-backup-tool/docker-compose.yml`` and rclone itself is deployed to the 
base image in ``gigadb/app/tools/dataset-backup-tool/Dockerfile``.

### Scripts

In order to reduce human error by:
 * making dry-run mode the default mode
 * forcing use of --verbose (because rclone shows no logging at all otherwise)  
 * asking confirmation before deleting something
 * reducing opportunities for operator to make typo or use wrong values

we need to:

 * wrap the ``rclone`` commands within thin wrapper scripts:
    * ``gigadb/app/tools/dataset-backup-tool/scripts/sync_files.sh`` for the incremental backup
    * ``gigadb/app/tools/dataset-backup-tool/scripts/delete_files.sh`` for deleting a file
 * centralize variables definition to be used by scripts in one place:
    * ``gigadb/app/tools/dataset-backup-tool/config/variables``
  
The latter file is git-ignored and is created from example ``gigadb/app/tools/dataset-backup-tool/config/variables.example`` by copying it:
```
$ cd gigadb/app/tools/dataset-backup-tool
$ cp config/variables.example config/variable
```
The default values from the example should work for testing purpose.

#### Testing the variables setup

There is additional smoke test, part of the ``rclone-setup`` group, to check a ``config/variable`` file exists and is not setup 
with production bucket.

```
$ cd gigadb/app/tools/dataset-backup-tool
$ docker-compose run --rm backup_tool ./vendor/bin/codecept run -g rclone-setup tests/functional
```

#### Using the scripts

by default, --dry-run mode is active.

On a developer environment, we will use docker-compose. 
On a production environment (CNGB backup server), we will use the script directly for now.
In the examples below we use ``/app/scripts/sync_files.sh``, but it works exactly the same way for the other script
``/app/scripts/delete_files.sh``

```
$ cd gigadb/app/tools/dataset-backup-tool
$ docker-compose run --rm backup_tool /app/scripts/sync_files.sh
```

When confident the output shows what you want to happen, you can enable the verbose mode to proceed for real:
```
$ cd gigadb/app/tools/dataset-backup-tool
$ docker-compose run --rm backup_tool /app/scripts/sync_files.sh --verbose
```

>**Note 1:** using ``-v`` instead of ``--verbose`` is possible.

>**Note 2:** the deletion script is more interactive as it prompts the user for the file to delete and then ask for confirmation.









